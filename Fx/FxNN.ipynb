{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Code to improve my bot: https://github.com/Norbaeocystin/FxBot\n",
    "Date: December 2018\n",
    "Author: Rastislav Baran\n",
    "Usage: to improve profitable dates generated by bot\n",
    "\n",
    "Here are few potential problems to make analysis less profitable trades than unprofitable\n",
    "\n",
    "Example of usage:\n",
    "\n",
    "X, Y = get_structured_data(3600)\n",
    "\n",
    "rnn = NNModel()\n",
    "rnn.fit(X,Y, generator = True)\n",
    "\n",
    "x, y = generate_random_dataset(X,Y)\n",
    "predicted = rnn.sess.run(rnn.predictions, feed_dict = {rnn.X: x} )\n",
    "#for all dataseet\n",
    "X_normalized = normalize_maxmin(X)\n",
    "predicted = rnn.sess.run(rnn.predictions, feed_dict = {rnn.X: X} )\n",
    "'''\n",
    "import datetime\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "# Connectio URI can be in shape mongodb://<username>:<password>@<ip>:<port>/<authenticationDatabase>')\n",
    "CONNECTION = MongoClient('localhost')\n",
    "db = CONNECTION.Bot\n",
    "FxData = db.FxData\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format = '%(asctime)s %(name)s %(levelname)s %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "\n",
    "def get_info_about_trades():\n",
    "    '''\n",
    "    returns: <dict>, profitable trades and unprofitable with sum profits and losses as dict\n",
    "    '''\n",
    "    return FxData.aggregate([{'$facet':{'loss':[{ '$match': { 'order': { '$exists': True }, 'profit' :{'$lt':12} }},{'$count': \"No\"}], \n",
    "                                        'profitable':[{ '$match': { 'order': { '$exists': True }, 'profit' :{'$gt':12} }},{'$count': \"No\"}], \n",
    "                                        'PL':[{ '$match': { 'order': { '$exists': True } }},{ '$group': { '_id' : None, 'sum' : { '$sum': \"$profit\" }}}]}\n",
    "                             }]).next()\n",
    "\n",
    "def get_trades():\n",
    "    '''\n",
    "    function which retuns list of dictionaries with data about closed trades\n",
    "    returns: <list>, list of dictionaries with data about closed trades\n",
    "    '''\n",
    "    return list(FxData.aggregate([{ '$match': { 'order': { '$exists': True }}}]))\n",
    "\n",
    "def get_structured_data(time = 100, limit = 0):\n",
    "    '''\n",
    "    Function to get structured data from MongoDB, please it can take time ...\n",
    "    returns: <tuple>, tuple: <numpy.array>, <numpy.array> or if you want: features, labels\n",
    "        \n",
    "    args:\n",
    "        time: <int>, how long features ( in this case timeserie) will be long in seconds\n",
    "        limit: <int>, positive integer to limit number of trades if necessary\n",
    "    '''\n",
    "    trades = get_trades()\n",
    "    if limit != 0 and limit > 0:\n",
    "        trades = trades[:limit]\n",
    "    #generate labels\n",
    "    profits = [item.get('profit') for item in trades]\n",
    "    logger.debug('Gets {} trades'.format(len(profits)))\n",
    "    #convert list profits and losses to binary\n",
    "    labels = np.array([[(0 if item < 0 else 1)] for item in profits]).astype(np.uint8)\n",
    "    # features\n",
    "    times = [item.get('Time') for item in trades]\n",
    "    features = []\n",
    "    logger.debug('Labels done. Working on features')\n",
    "    # fetching data for features and structuring them\n",
    "    for ind, item in enumerate(times):\n",
    "        # lower or equal time that in item, only price to get, reversed it by sorting, limit size of data and reversed it again \n",
    "        x = list(FxData.find({'Time':{'$lte':item}},{\"Price\":1, '_id':0}).sort('Time', pymongo.DESCENDING).limit(time))[::-1]\n",
    "        if len(x) != time:\n",
    "            logger.debug('Data are shorter for item {}'.format(ind))\n",
    "            break\n",
    "        features.append([item.get('Price') for item in x])\n",
    "        if ind % 10 == 0:\n",
    "            logger.debug('Done structuring {} trades'.format(ind))\n",
    "    features = np.array(features).astype(np.float32)\n",
    "    logger.debug('Your data are prepared')\n",
    "    return features, labels\n",
    "\n",
    "def normalize_maxmin(X):\n",
    "    '''\n",
    "    MaxMinNormalizer\n",
    "    return: <numpy.ndarray>, with values between 0 and 1\n",
    "    \n",
    "    args:\n",
    "        X: <numpy.ndarray>, features, labels whatever\n",
    "    '''\n",
    "    return MinMaxScaler().fit_transform(X)\n",
    "\n",
    "def generate_random_dataset(X, Y, ratio_of_profit = 0.7):\n",
    "    '''\n",
    "    one solution how to generate dataset with ration 50 % of profitable trades and loss trades\n",
    "    return: <list>, list of shuffled features and labels as numpy.ndarray\n",
    "    \n",
    "    args:\n",
    "        X: <numpy.ndarray>, features\n",
    "        Y: <numpy.ndarray>, labels with shape (x, 1)\n",
    "        ratio_of_profit: <float>, between 0 to 1, how many of profitable trades to use\n",
    "    '''\n",
    "    #returns indices of profitable trades\n",
    "    indices_profitable = np.argwhere(Y == 1)[:,0]\n",
    "    indices_profitable = np.random.choice(indices_profitable, size =  int(indices_profitable.shape[0]* ratio_of_profit))\n",
    "    #returns profitable trades\n",
    "    profitable_features = np.take(X,[indices_profitable], axis =0)[0]\n",
    "    #now for loss trades\n",
    "    indices_loss = np.argwhere(Y == 0)[:,0]\n",
    "    indices_loss = np.random.choice(indices_loss, size =  int(indices_profitable.shape[0]* ratio_of_profit ))\n",
    "    #returns profitable trades\n",
    "    loss_features = np.take(X,[indices_loss], axis =0)[0]\n",
    "    #concatenate\n",
    "    features = np.concatenate((profitable_features, loss_features), axis = 0)\n",
    "    profits = np.array([[1]] * profitable_features.shape[0])\n",
    "    losses = np.array([[0]] * loss_features.shape[0])\n",
    "    labels = np.concatenate([profits, losses], axis = 0)\n",
    "    #shuffle dataset\n",
    "    features = normalize_maxmin(features)\n",
    "    return shuffle(features, labels)\n",
    "\n",
    "\n",
    "class NNModel:\n",
    "    \n",
    "    def __init__(self, input_dim = 3600, output_dim = 1, learning_rate = 0.00001, dropout = 0.5):\n",
    "        self.X  = tf.placeholder(tf.float32, shape = [None, input_dim], name = 'X')\n",
    "        self.Y = tf.placeholder(tf.float32, shape = [None, output_dim], name = 'Y')\n",
    "        self.logdir = 'logs/RNN_with_summaries'\n",
    "        self.learning_rate = learning_rate\n",
    "        self.dropout = dropout\n",
    "        self.keep_prob = tf.placeholder_with_default(1.0, shape=())\n",
    "        #NN\n",
    "        '''\n",
    "        posibility to add conv1d filters\n",
    "        \n",
    "        #input\n",
    "        i = tf.constant([1, 0, 2, 3, 0, 1, 1,0], dtype=tf.float32, name='i')\n",
    "        #kernel\n",
    "        k = tf.constant([0, 1, 0], dtype=tf.float32, name='k')\n",
    "        #reshaping\n",
    "        data   = tf.reshape(i, [1, int(i.shape[0]), 1], name='data')\n",
    "        kernel = tf.reshape(k, [int(k.shape[0]), 1, 1], name='kernel')\n",
    "        #squeezing is neccessary to remove one dimension\n",
    "        res = tf.squeeze(tf.nn.conv1d(data, kernel, 2, 'SAME'))\n",
    "        '''\n",
    "        self.fc1 = tf.contrib.layers.fully_connected(self.X, 2048, activation_fn = tf.nn.relu)\n",
    "        self.d1 = tf.nn.dropout(self.fc1, self.keep_prob)\n",
    "        self.fc2 = tf.contrib.layers.fully_connected(self.d1, 1024, activation_fn = tf.nn.relu) \n",
    "        self.fc3 = tf.contrib.layers.fully_connected(self.fc2, 1024, activation_fn = tf.nn.relu) \n",
    "        self.fc4 = tf.contrib.layers.fully_connected(self.fc3, 1024, activation_fn = tf.nn.relu) \n",
    "        self.d2 = tf.nn.dropout(self.fc4, self.keep_prob)\n",
    "        self.fc5 = tf.contrib.layers.fully_connected(self.d2, 32, activation_fn = tf.nn.relu) \n",
    "        self.prediction = tf.layers.dense(self.fc5, 1, activation = tf.sigmoid)\n",
    "        self.cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = self.prediction, labels = self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.cost)\n",
    "        self.predicted_class = tf.greater(self.prediction,0.5)\n",
    "        self.correct = tf.equal(self.predicted_class, tf.equal(self.Y,1.0))\n",
    "        self.accuracy = tf.reduce_mean( tf.cast(self.correct, 'float') )\n",
    "        self.init_op = tf.global_variables_initializer()\n",
    "        self.config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "        self.sess = tf.Session(config = self.config)\n",
    "        self.accuracy_scalar = tf.summary.scalar('accuracy', self.accuracy)\n",
    "    \n",
    "    def fit(self, X, Y, epochs = 100000,every = 1000, generator = False, log = 'Forex_NN_log'):\n",
    "        '''\n",
    "        optimizes weights\n",
    "        args:\n",
    "          X: <numpy.array>, features \n",
    "          Y: <numpy.array>, labels\n",
    "          epochs: <int>, number of epochs\n",
    "          every: <int>, how often print message with Epoch and Loss values\n",
    "          folder: <string>, name of folder where to store data for TensorBoard\n",
    "          batch_size: <int>, size of features array, size of features sample\n",
    "        '''\n",
    "        self.sess.run(self.init_op)\n",
    "        logger.debug('Initializing')\n",
    "        summary_writer = tf.summary.FileWriter(log, self.sess.graph)\n",
    "        for i in range(epochs):\n",
    "            if generator:\n",
    "                x, y = generate_random_dataset(X,Y)\n",
    "                _, l,a, acc = self.sess.run([self.optimizer, self.cost,self.accuracy, self.accuracy_scalar], \n",
    "                                            feed_dict = {self.X: x, self.Y: y, self.keep_prob: self.dropout})\n",
    "                summary_writer.add_summary(acc, i)\n",
    "                if i % every == 0:\n",
    "                    print('[ {} ] Epoch {} Loss: {:.7f} accuracy {}'.format(time.ctime(), i, l,a)) \n",
    "                    \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        predict values\n",
    "        '''\n",
    "        y_hat = self.sess.run(self.prediction, feed_dict = {self.X: X})\n",
    "        return y_hat\n",
    "    \n",
    "    def get_compare(self,prediction, target):\n",
    "        '''\n",
    "        compare predicted values with targeted values\n",
    "        returns: <dict>, {'Profitable Trades': <int>, 'Lost_trades': <int>}\n",
    "        '''\n",
    "        profitable = np.argwhere(target == 1)[:,0]\n",
    "        calculated_profitable = np.argwhere(np.round(prediction) == 1)[:,0]\n",
    "        set_profitable = set(profitable)\n",
    "        really_profitable_trades = set_profitable.intersection(calculated_profitable)\n",
    "        lost = len(calculated_profitable) - len(really_profitable_trades)\n",
    "        return {'Profitable Trades': len(really_profitable_trades), 'Lost_trades': lost}\n",
    "        \n",
    "   \n",
    "    def variable_summaries(self, var):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        with tf.name_scope('summaries'):\n",
    "            mean = tf.reduce_mean(var)\n",
    "            tf.summary.scalar('mean', mean)\n",
    "            with tf.name_scope('stddev'):\n",
    "                stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "            tf.summary.scalar('stddev', stddev)\n",
    "            tf.summary.scalar('max', tf.reduce_max(var))\n",
    "            tf.summary.scalar('min', tf.reduce_min(var))\n",
    "            tf.summary.histogram('histogram', var)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.load('X_3600.npy'),np.load('Y_3600.npy'),\n",
    "x, y = generate_random_dataset(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-30 04:15:43,066 __main__ DEBUG Initializing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Sun Dec 30 04:15:43 2018 ] Epoch 0 Loss: 0.6782134 accuracy 0.48148149251937866\n",
      "[ Sun Dec 30 04:19:05 2018 ] Epoch 5000 Loss: 0.6386988 accuracy 0.4444444477558136\n",
      "[ Sun Dec 30 04:22:27 2018 ] Epoch 10000 Loss: 0.5939413 accuracy 0.7037037014961243\n",
      "[ Sun Dec 30 04:25:47 2018 ] Epoch 15000 Loss: 0.6296215 accuracy 0.5925925970077515\n",
      "[ Sun Dec 30 04:29:05 2018 ] Epoch 20000 Loss: 0.6319671 accuracy 0.6666666865348816\n",
      "[ Sun Dec 30 04:32:21 2018 ] Epoch 25000 Loss: 0.6309261 accuracy 0.5925925970077515\n",
      "[ Sun Dec 30 04:35:36 2018 ] Epoch 30000 Loss: 0.6462585 accuracy 0.5555555820465088\n",
      "[ Sun Dec 30 04:38:55 2018 ] Epoch 35000 Loss: 0.6669331 accuracy 0.5925925970077515\n",
      "[ Sun Dec 30 04:42:16 2018 ] Epoch 40000 Loss: 0.5976955 accuracy 0.6296296119689941\n",
      "[ Sun Dec 30 04:45:33 2018 ] Epoch 45000 Loss: 0.5928024 accuracy 0.6666666865348816\n",
      "[ Sun Dec 30 04:48:54 2018 ] Epoch 50000 Loss: 0.6152413 accuracy 0.6666666865348816\n",
      "[ Sun Dec 30 04:52:16 2018 ] Epoch 55000 Loss: 0.5450385 accuracy 0.8148148059844971\n",
      "[ Sun Dec 30 04:55:37 2018 ] Epoch 60000 Loss: 0.5818670 accuracy 0.7037037014961243\n",
      "[ Sun Dec 30 04:58:57 2018 ] Epoch 65000 Loss: 0.5290233 accuracy 0.8888888955116272\n",
      "[ Sun Dec 30 05:02:21 2018 ] Epoch 70000 Loss: 0.6183283 accuracy 0.7777777910232544\n",
      "[ Sun Dec 30 05:05:44 2018 ] Epoch 75000 Loss: 0.5866600 accuracy 0.8148148059844971\n",
      "[ Sun Dec 30 05:09:04 2018 ] Epoch 80000 Loss: 0.5740160 accuracy 0.7407407164573669\n",
      "[ Sun Dec 30 05:12:31 2018 ] Epoch 85000 Loss: 0.5372048 accuracy 0.8518518805503845\n",
      "[ Sun Dec 30 05:15:58 2018 ] Epoch 90000 Loss: 0.5923303 accuracy 0.7037037014961243\n",
      "[ Sun Dec 30 05:19:18 2018 ] Epoch 95000 Loss: 0.5554362 accuracy 0.8518518805503845\n",
      "[ Sun Dec 30 05:22:35 2018 ] Epoch 100000 Loss: 0.5672827 accuracy 0.8148148059844971\n",
      "[ Sun Dec 30 05:25:49 2018 ] Epoch 105000 Loss: 0.5541858 accuracy 0.8888888955116272\n",
      "[ Sun Dec 30 05:29:12 2018 ] Epoch 110000 Loss: 0.4764297 accuracy 1.0\n",
      "[ Sun Dec 30 05:32:33 2018 ] Epoch 115000 Loss: 0.5206765 accuracy 0.8888888955116272\n",
      "[ Sun Dec 30 05:35:48 2018 ] Epoch 120000 Loss: 0.5510393 accuracy 0.8518518805503845\n",
      "[ Sun Dec 30 05:39:11 2018 ] Epoch 125000 Loss: 0.4696750 accuracy 1.0\n",
      "[ Sun Dec 30 05:42:34 2018 ] Epoch 130000 Loss: 0.5373315 accuracy 0.8888888955116272\n",
      "[ Sun Dec 30 05:45:55 2018 ] Epoch 135000 Loss: 0.5049474 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 05:49:16 2018 ] Epoch 140000 Loss: 0.5422650 accuracy 0.8518518805503845\n",
      "[ Sun Dec 30 05:52:36 2018 ] Epoch 145000 Loss: 0.5083679 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 05:55:55 2018 ] Epoch 150000 Loss: 0.5395722 accuracy 0.8888888955116272\n",
      "[ Sun Dec 30 05:59:13 2018 ] Epoch 155000 Loss: 0.5054228 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 06:02:29 2018 ] Epoch 160000 Loss: 0.5692359 accuracy 0.7037037014961243\n",
      "[ Sun Dec 30 06:05:46 2018 ] Epoch 165000 Loss: 0.5318701 accuracy 0.8518518805503845\n",
      "[ Sun Dec 30 06:09:01 2018 ] Epoch 170000 Loss: 0.5036234 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 06:12:16 2018 ] Epoch 175000 Loss: 0.5402930 accuracy 0.8518518805503845\n",
      "[ Sun Dec 30 06:15:32 2018 ] Epoch 180000 Loss: 0.5570180 accuracy 0.8518518805503845\n",
      "[ Sun Dec 30 06:18:47 2018 ] Epoch 185000 Loss: 0.4992064 accuracy 0.9629629850387573\n",
      "[ Sun Dec 30 06:22:01 2018 ] Epoch 190000 Loss: 0.5086197 accuracy 0.8888888955116272\n",
      "[ Sun Dec 30 06:25:15 2018 ] Epoch 195000 Loss: 0.4837150 accuracy 0.9629629850387573\n",
      "[ Sun Dec 30 06:28:30 2018 ] Epoch 200000 Loss: 0.4938537 accuracy 0.9629629850387573\n",
      "[ Sun Dec 30 06:31:44 2018 ] Epoch 205000 Loss: 0.5380030 accuracy 0.8888888955116272\n",
      "[ Sun Dec 30 06:34:57 2018 ] Epoch 210000 Loss: 0.5103146 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 06:38:11 2018 ] Epoch 215000 Loss: 0.4901622 accuracy 0.9629629850387573\n",
      "[ Sun Dec 30 06:41:24 2018 ] Epoch 220000 Loss: 0.5664321 accuracy 0.7037037014961243\n",
      "[ Sun Dec 30 06:44:37 2018 ] Epoch 225000 Loss: 0.4692215 accuracy 1.0\n",
      "[ Sun Dec 30 06:47:51 2018 ] Epoch 230000 Loss: 0.5002255 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 06:51:04 2018 ] Epoch 235000 Loss: 0.5285591 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 06:54:16 2018 ] Epoch 240000 Loss: 0.6343554 accuracy 0.5925925970077515\n",
      "[ Sun Dec 30 06:57:29 2018 ] Epoch 245000 Loss: 0.4703328 accuracy 1.0\n",
      "[ Sun Dec 30 07:00:42 2018 ] Epoch 250000 Loss: 0.5295004 accuracy 0.8888888955116272\n",
      "[ Sun Dec 30 07:03:54 2018 ] Epoch 255000 Loss: 0.5680160 accuracy 0.8148148059844971\n",
      "[ Sun Dec 30 07:07:07 2018 ] Epoch 260000 Loss: 0.5248942 accuracy 0.8518518805503845\n",
      "[ Sun Dec 30 07:10:19 2018 ] Epoch 265000 Loss: 0.4729583 accuracy 1.0\n",
      "[ Sun Dec 30 07:13:32 2018 ] Epoch 270000 Loss: 0.5325502 accuracy 0.8888888955116272\n",
      "[ Sun Dec 30 07:16:44 2018 ] Epoch 275000 Loss: 0.4973067 accuracy 0.9629629850387573\n",
      "[ Sun Dec 30 07:19:57 2018 ] Epoch 280000 Loss: 0.5516508 accuracy 0.8888888955116272\n",
      "[ Sun Dec 30 07:23:09 2018 ] Epoch 285000 Loss: 0.4990535 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 07:26:22 2018 ] Epoch 290000 Loss: 0.5051571 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 07:29:34 2018 ] Epoch 295000 Loss: 0.5199071 accuracy 0.8888888955116272\n",
      "[ Sun Dec 30 07:32:47 2018 ] Epoch 300000 Loss: 0.5119607 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 07:36:00 2018 ] Epoch 305000 Loss: 0.5409505 accuracy 0.8518518805503845\n",
      "[ Sun Dec 30 07:39:14 2018 ] Epoch 310000 Loss: 0.5328374 accuracy 0.8888888955116272\n",
      "[ Sun Dec 30 07:42:27 2018 ] Epoch 315000 Loss: 0.5133861 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 07:45:41 2018 ] Epoch 320000 Loss: 0.7247485 accuracy 0.37037035822868347\n",
      "[ Sun Dec 30 07:48:55 2018 ] Epoch 325000 Loss: 0.5249037 accuracy 0.8888888955116272\n",
      "[ Sun Dec 30 07:52:09 2018 ] Epoch 330000 Loss: 0.4947052 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 07:55:23 2018 ] Epoch 335000 Loss: 0.6042758 accuracy 0.6296296119689941\n",
      "[ Sun Dec 30 07:58:36 2018 ] Epoch 340000 Loss: 0.4902020 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 08:01:50 2018 ] Epoch 345000 Loss: 0.4900533 accuracy 0.9629629850387573\n",
      "[ Sun Dec 30 08:05:05 2018 ] Epoch 350000 Loss: 0.5163766 accuracy 0.8148148059844971\n",
      "[ Sun Dec 30 08:08:19 2018 ] Epoch 355000 Loss: 0.5177056 accuracy 0.8888888955116272\n",
      "[ Sun Dec 30 08:11:33 2018 ] Epoch 360000 Loss: 0.5454354 accuracy 0.8888888955116272\n",
      "[ Sun Dec 30 08:14:48 2018 ] Epoch 365000 Loss: 0.5160921 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 08:18:01 2018 ] Epoch 370000 Loss: 0.5505266 accuracy 0.8518518805503845\n",
      "[ Sun Dec 30 08:21:15 2018 ] Epoch 375000 Loss: 0.5164734 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 08:24:29 2018 ] Epoch 380000 Loss: 0.5186650 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 08:27:42 2018 ] Epoch 385000 Loss: 0.6078402 accuracy 0.7777777910232544\n",
      "[ Sun Dec 30 08:30:55 2018 ] Epoch 390000 Loss: 0.5134923 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 08:34:07 2018 ] Epoch 395000 Loss: 0.4911718 accuracy 0.9629629850387573\n",
      "[ Sun Dec 30 08:37:20 2018 ] Epoch 400000 Loss: 0.5466481 accuracy 0.8148148059844971\n",
      "[ Sun Dec 30 08:40:33 2018 ] Epoch 405000 Loss: 0.4813011 accuracy 1.0\n",
      "[ Sun Dec 30 08:43:45 2018 ] Epoch 410000 Loss: 0.4916143 accuracy 0.9629629850387573\n",
      "[ Sun Dec 30 08:46:57 2018 ] Epoch 415000 Loss: 0.4838601 accuracy 1.0\n",
      "[ Sun Dec 30 08:50:10 2018 ] Epoch 420000 Loss: 0.5249305 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 08:53:22 2018 ] Epoch 425000 Loss: 0.4701581 accuracy 1.0\n",
      "[ Sun Dec 30 08:56:34 2018 ] Epoch 430000 Loss: 0.4912297 accuracy 0.9629629850387573\n",
      "[ Sun Dec 30 08:59:46 2018 ] Epoch 435000 Loss: 0.4898260 accuracy 0.9629629850387573\n",
      "[ Sun Dec 30 09:02:59 2018 ] Epoch 440000 Loss: 0.5157875 accuracy 0.8888888955116272\n",
      "[ Sun Dec 30 09:06:14 2018 ] Epoch 445000 Loss: 0.4857565 accuracy 0.9629629850387573\n",
      "[ Sun Dec 30 09:09:29 2018 ] Epoch 450000 Loss: 0.5966531 accuracy 0.7777777910232544\n",
      "[ Sun Dec 30 09:12:45 2018 ] Epoch 455000 Loss: 0.4997095 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 09:16:00 2018 ] Epoch 460000 Loss: 0.4682106 accuracy 1.0\n",
      "[ Sun Dec 30 09:19:16 2018 ] Epoch 465000 Loss: 0.5945070 accuracy 0.8148148059844971\n",
      "[ Sun Dec 30 09:22:31 2018 ] Epoch 470000 Loss: 0.5198889 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 09:25:46 2018 ] Epoch 475000 Loss: 0.4700481 accuracy 1.0\n",
      "[ Sun Dec 30 09:29:01 2018 ] Epoch 480000 Loss: 0.4995462 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 09:32:15 2018 ] Epoch 485000 Loss: 0.4843249 accuracy 0.9629629850387573\n",
      "[ Sun Dec 30 09:35:29 2018 ] Epoch 490000 Loss: 0.4794686 accuracy 0.9629629850387573\n",
      "[ Sun Dec 30 09:38:44 2018 ] Epoch 495000 Loss: 0.4978165 accuracy 0.8888888955116272\n",
      "[ Sun Dec 30 09:41:58 2018 ] Epoch 500000 Loss: 0.5028132 accuracy 0.9629629850387573\n",
      "[ Sun Dec 30 09:45:12 2018 ] Epoch 505000 Loss: 0.5516664 accuracy 0.8518518805503845\n",
      "[ Sun Dec 30 09:48:25 2018 ] Epoch 510000 Loss: 0.4909741 accuracy 0.9629629850387573\n",
      "[ Sun Dec 30 09:51:38 2018 ] Epoch 515000 Loss: 0.5050139 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 09:54:52 2018 ] Epoch 520000 Loss: 0.5508488 accuracy 0.8518518805503845\n",
      "[ Sun Dec 30 09:58:07 2018 ] Epoch 525000 Loss: 0.5084521 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 10:01:21 2018 ] Epoch 530000 Loss: 0.4913494 accuracy 0.9629629850387573\n",
      "[ Sun Dec 30 10:04:35 2018 ] Epoch 535000 Loss: 0.5109468 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 10:07:48 2018 ] Epoch 540000 Loss: 0.5167475 accuracy 0.8888888955116272\n",
      "[ Sun Dec 30 10:11:02 2018 ] Epoch 545000 Loss: 0.5367919 accuracy 0.8888888955116272\n",
      "[ Sun Dec 30 10:14:16 2018 ] Epoch 550000 Loss: 0.4972716 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 10:17:31 2018 ] Epoch 555000 Loss: 0.6498939 accuracy 0.5925925970077515\n",
      "[ Sun Dec 30 10:20:45 2018 ] Epoch 560000 Loss: 0.4680430 accuracy 1.0\n",
      "[ Sun Dec 30 10:23:59 2018 ] Epoch 565000 Loss: 0.4821784 accuracy 0.9629629850387573\n",
      "[ Sun Dec 30 10:27:13 2018 ] Epoch 570000 Loss: 0.5249717 accuracy 0.8888888955116272\n",
      "[ Sun Dec 30 10:30:27 2018 ] Epoch 575000 Loss: 0.5055904 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 10:33:40 2018 ] Epoch 580000 Loss: 0.4867742 accuracy 0.9629629850387573\n",
      "[ Sun Dec 30 10:36:53 2018 ] Epoch 585000 Loss: 0.4714940 accuracy 1.0\n",
      "[ Sun Dec 30 10:40:06 2018 ] Epoch 590000 Loss: 0.4860456 accuracy 0.9629629850387573\n",
      "[ Sun Dec 30 10:43:19 2018 ] Epoch 595000 Loss: 0.4915645 accuracy 0.9629629850387573\n",
      "[ Sun Dec 30 10:46:32 2018 ] Epoch 600000 Loss: 0.4689045 accuracy 1.0\n",
      "[ Sun Dec 30 10:49:46 2018 ] Epoch 605000 Loss: 0.5274131 accuracy 0.8518518805503845\n",
      "[ Sun Dec 30 10:53:01 2018 ] Epoch 610000 Loss: 0.5548064 accuracy 0.8518518805503845\n",
      "[ Sun Dec 30 10:56:18 2018 ] Epoch 615000 Loss: 0.4927784 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 10:59:35 2018 ] Epoch 620000 Loss: 0.5274072 accuracy 0.8518518805503845\n",
      "[ Sun Dec 30 11:02:51 2018 ] Epoch 625000 Loss: 0.5102509 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 11:06:07 2018 ] Epoch 630000 Loss: 0.4909067 accuracy 0.9629629850387573\n",
      "[ Sun Dec 30 11:09:23 2018 ] Epoch 635000 Loss: 0.4740531 accuracy 1.0\n",
      "[ Sun Dec 30 11:12:41 2018 ] Epoch 640000 Loss: 0.4682275 accuracy 1.0\n",
      "[ Sun Dec 30 11:16:04 2018 ] Epoch 645000 Loss: 0.5494518 accuracy 0.8518518805503845\n",
      "[ Sun Dec 30 11:19:21 2018 ] Epoch 650000 Loss: 0.4914446 accuracy 0.9629629850387573\n",
      "[ Sun Dec 30 11:22:41 2018 ] Epoch 655000 Loss: 0.4910233 accuracy 0.9629629850387573\n",
      "[ Sun Dec 30 11:26:01 2018 ] Epoch 660000 Loss: 0.4680317 accuracy 1.0\n",
      "[ Sun Dec 30 11:29:22 2018 ] Epoch 665000 Loss: 0.5340452 accuracy 0.8888888955116272\n",
      "[ Sun Dec 30 11:32:43 2018 ] Epoch 670000 Loss: 0.5243171 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 11:36:04 2018 ] Epoch 675000 Loss: 0.4833691 accuracy 0.9629629850387573\n",
      "[ Sun Dec 30 11:39:24 2018 ] Epoch 680000 Loss: 0.5783018 accuracy 0.8148148059844971\n",
      "[ Sun Dec 30 11:42:43 2018 ] Epoch 685000 Loss: 0.4842117 accuracy 0.9629629850387573\n",
      "[ Sun Dec 30 11:46:03 2018 ] Epoch 690000 Loss: 0.5142328 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 11:49:21 2018 ] Epoch 695000 Loss: 0.5133134 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 11:52:40 2018 ] Epoch 700000 Loss: 0.4918640 accuracy 0.9629629850387573\n",
      "[ Sun Dec 30 11:56:00 2018 ] Epoch 705000 Loss: 0.5509727 accuracy 0.8518518805503845\n",
      "[ Sun Dec 30 11:59:21 2018 ] Epoch 710000 Loss: 0.4909960 accuracy 0.9629629850387573\n",
      "[ Sun Dec 30 12:02:41 2018 ] Epoch 715000 Loss: 0.5110878 accuracy 0.8888888955116272\n",
      "[ Sun Dec 30 12:06:00 2018 ] Epoch 720000 Loss: 0.5138199 accuracy 0.9259259104728699\n",
      "[ Sun Dec 30 12:09:22 2018 ] Epoch 725000 Loss: 0.6294923 accuracy 0.7037037014961243\n",
      "[ Sun Dec 30 12:12:45 2018 ] Epoch 730000 Loss: 0.5594801 accuracy 0.8148148059844971\n",
      "[ Sun Dec 30 12:16:03 2018 ] Epoch 735000 Loss: 0.4724264 accuracy 1.0\n",
      "[ Sun Dec 30 12:19:24 2018 ] Epoch 740000 Loss: 0.4873747 accuracy 0.9629629850387573\n",
      "[ Sun Dec 30 12:22:43 2018 ] Epoch 745000 Loss: 0.4680701 accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "rnn = NNModel()\n",
    "rnn.fit(X,Y, epochs = 750000, every = 5000, generator = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalized = normalize_maxmin(X)\n",
    "pred = rnn.predict(X_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compare(prediction, target):\n",
    "    profitable = np.argwhere(target == 1)[:,0]\n",
    "    calculated_profitable = np.argwhere(np.round(prediction) == 1)[:,0]\n",
    "    set_profitable = set(profitable)\n",
    "    really_profitable_trades = set_profitable.intersection(calculated_profitable)\n",
    "    lost = len(calculated_profitable) - len(really_profitable_trades)\n",
    "    return {'Profitable Trades': len(really_profitable_trades), 'Lost_trades': lost}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Model/NN_FxData/model_13_00'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(rnn.sess, 'Model/NN_FxData/model_13_00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Profitable Trades': 24, 'Lost_trades': 14}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_compare(pred, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = Y\n",
    "prediction = npred\n",
    "profitable = np.argwhere(target == 1)[:,0]\n",
    "calculated_profitable = np.argwhere(np.round(prediction == 1)[:,0]\n",
    "set_profitable = set(profitable)\n",
    "really_profitable_trades = set_profitable.intersection(calculated_profitable)\n",
    "lost = len(calculated_profitable) - len(really_profitable_trades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10,  33,  54,  63,  64,  79,  82,  83,  84,  85, 112, 142, 165,\n",
       "       169, 171, 197, 226, 235, 238, 272, 273, 296, 300, 301])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profitable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10,  82,  83,  84,  85, 112, 142, 165, 169, 171, 197, 226, 235,\n",
       "       238])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculated_profitable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

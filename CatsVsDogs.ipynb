{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My attempt to make CNN able to clasify dogs and cats<br><br>\n",
    "Important note dataset have been downloaded from kaggle and extracted to train folder ... <br><br>\n",
    "Lets start with neccessary imports:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "import skimage\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code to show avaivable device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 3396653073226691788, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 5908987904\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 14827356250583959885\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:02:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to make datates of cats and dogs, resize images convert them to numpy arrays and merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cats(size = 500, start = 0):\n",
    "    '''\n",
    "    for example if you want first 50 images of cats resized to 200 x 200 pixels as grayscaled numpy array\n",
    "    set size = 50 and start = 0\n",
    "    if you want images from 50 - 100\n",
    "    set size 50 and start 50\n",
    "    '''\n",
    "    cats = []\n",
    "    for i in range(start, start + size):\n",
    "        img = Image.open('train/cat.{}.jpg'.format(i))\n",
    "        img = img.resize(size = (200,200))\n",
    "        img = skimage.color.rgb2gray(skimage.img_as_float(img))\n",
    "        cats.append(img)\n",
    "    return np.array(cats, dtype='float32')\n",
    "\n",
    "def get_dogs(size = 500, start = 0):\n",
    "    '''\n",
    "    for example if you want first 50 images of dogs resized to 200 x 200 pixels as grayscaled numpy array\n",
    "    set size = 50 and start = 0\n",
    "    if you want images from 50 - 100\n",
    "    set size 50 and start 50\n",
    "    '''\n",
    "    dogs = []\n",
    "    for i in range(start, start + size):\n",
    "        img = Image.open('train/dog.{}.jpg'.format(i))\n",
    "        img = img.resize(size = (200,200))\n",
    "        img = skimage.color.rgb2gray(skimage.img_as_float(img))\n",
    "        dogs.append(img)\n",
    "    return np.array(dogs, dtype='float32')\n",
    "\n",
    "def randomizer():\n",
    "    animalKind = {'cat':[1,0], 'dog':[0,1]}\n",
    "    catOrDog = random.choice(['cat', 'dog'])\n",
    "    pictureIndex = random.choice(range(9999))\n",
    "    img = Image.open('train/{}.{}.jpg'.format(catOrDog, pictureIndex))\n",
    "    img = img.resize(size = (200,200))\n",
    "    img = skimage.color.rgb2gray(skimage.img_as_float(img))\n",
    "    return {'y':animalKind.get(catOrDog), 'x':img}\n",
    "\n",
    "def random_X_and_Y(size = 1000):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(size):\n",
    "        data = randomizer()\n",
    "        X.append(data.get('x'))\n",
    "        Y.append(data.get('y'))\n",
    "    return np.array(X, dtype = 'float32').reshape(-1,200,200,1), np.array(Y, dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = random_X_and_Y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 200, 200, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats = get_cats()\n",
    "dogs = get_dogs()\n",
    "X = np.concatenate((cats, dogs), axis = 0).reshape(-1,200,200,1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we need labels, we can do it like cat will be 0 and dog 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cats = np.array([[1,0]] * cats.shape[0])\n",
    "y_dogs = np.array([[0,1]] * dogs.shape[0])\n",
    "Y = np.concatenate((y_cats, y_dogs), axis = 0)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now real fun can begin :)<br>\n",
    "Here are lots of possibilities to tweek, change convolutional filter (one is for horizontal edges another one for vertical edges), number of neurons, activation functions, loss function ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(\n",
    "        device_count = {'GPU': 0}\n",
    "    )\n",
    "tf.reset_default_graph()\n",
    "X_ = tf.placeholder( dtype=tf.float32, shape=(1000, 200, 200,1))\n",
    "Y_ = tf.placeholder( dtype=tf.float32, shape=(1000, 2))\n",
    "bias = tf.Variable(tf.zeros([1024]), name=\"bias\")\n",
    "kernel_h = np.array([3, 3])\n",
    "kernel_h = [ [1,2,1], [0,0,0], [-1,-2,-1] ] # horizontal edges convolutional filter\n",
    "kernel_v = np.array([3, 3])\n",
    "kernel_v = [ [1,0,1], [2,0,-2], [-1,0,-1] ] # vertical edges convolutional filter\n",
    "with tf.name_scope('convolution'):\n",
    "    conv_w_h = tf.constant(kernel_h, dtype=tf.float32, shape=(3, 3,1,1))\n",
    "    conv_w_v = tf.constant(kernel_v, dtype=tf.float32, shape=(3, 3,1,1))    \n",
    "    # applying convolutional filter\n",
    "    output_h = tf.nn.conv2d(input=X_, filter=conv_w_h, strides= [1,2,2,1], padding='SAME')\n",
    "    # applying convolutional filter\n",
    "    output_v = tf.nn.conv2d(input=X_, filter=conv_w_v, strides= [1,2,2,1], padding='SAME')\n",
    "    #merging  both convolutional filter\n",
    "    output = tf.sqrt(tf.add(tf.square(output_h), tf.square(output_v)))\n",
    "    pool = tf.layers.max_pooling2d(inputs = output, pool_size=[2, 2], strides=2)\n",
    "    pool2flat = tf.reshape(pool,[-1, 50*50])\n",
    "    dense = tf.layers.dense(inputs = pool2flat, units=1024, activation=tf.nn.relu)\n",
    "    dense2 = tf.layers.dense(inputs = dense, units=512, activation=tf.nn.relu)\n",
    "    dense3 = tf.layers.dense(inputs = dense2, units=256, activation=tf.nn.relu)\n",
    "    dense4 = tf.layers.dense(inputs = dense3, units = 64, activation=tf.nn.sigmoid)\n",
    "    logits = tf.layers.dense(inputs = dense4, units=2, activation = tf.nn.sigmoid)\n",
    "    cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits = logits,labels=Y_)\n",
    "    cost = tf.reduce_mean(cross_entropy)\n",
    "    summary_cost = tf.summary.scalar('cost', cost)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.00001).minimize(cost)\n",
    "    accuracy, acc_op = tf.metrics.accuracy(labels = Y_, predictions = tf.round(logits))\n",
    "    summary_accuracy = tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start training our CNN. Hmm there is some difference between tf.sigmoid and tf.nn.sigmoid<br>\n",
    "to run tensorboard: <strong>tensorboard --logdir=/home/oktogen/Desktop/DeepLearningExperiments/CNN/CatsVsDogs/Logs<strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session starting Sun Nov 11 19:14:08 2018\n",
      "Time: Sun Nov 11 19:14:20 2018 Epoch: 0 Cost: 0.7225949764251709 Acc: 0.5040000081062317\n",
      "Time: Sun Nov 11 19:15:40 2018 Epoch: 10 Cost: 0.7159053087234497 Acc: 0.5024999976158142\n",
      "Time: Sun Nov 11 19:16:44 2018 Epoch: 20 Cost: 0.7104380130767822 Acc: 0.4938333332538605\n",
      "Time: Sun Nov 11 19:17:36 2018 Epoch: 30 Cost: 0.7066082954406738 Acc: 0.4950000047683716\n",
      "Time: Sun Nov 11 19:18:21 2018 Epoch: 40 Cost: 0.7056167125701904 Acc: 0.4959000051021576\n",
      "Time: Sun Nov 11 19:19:03 2018 Epoch: 50 Cost: 0.6994985342025757 Acc: 0.49658334255218506\n",
      "Time: Sun Nov 11 19:19:43 2018 Epoch: 60 Cost: 0.7000135779380798 Acc: 0.49707141518592834\n",
      "Time: Sun Nov 11 19:20:21 2018 Epoch: 70 Cost: 0.6969941854476929 Acc: 0.4974375069141388\n",
      "Time: Sun Nov 11 19:20:59 2018 Epoch: 80 Cost: 0.6966108083724976 Acc: 0.49772220849990845\n",
      "Time: Sun Nov 11 19:21:35 2018 Epoch: 90 Cost: 0.6949924826622009 Acc: 0.4979499876499176\n",
      "Time: Sun Nov 11 19:22:11 2018 Epoch: 100 Cost: 0.6942228674888611 Acc: 0.49813637137413025\n",
      "Time: Sun Nov 11 19:22:46 2018 Epoch: 110 Cost: 0.6922369599342346 Acc: 0.49829167127609253\n",
      "Time: Sun Nov 11 19:23:22 2018 Epoch: 120 Cost: 0.6914291977882385 Acc: 0.4984230697154999\n",
      "Time: Sun Nov 11 19:23:57 2018 Epoch: 130 Cost: 0.6911957263946533 Acc: 0.49853572249412537\n",
      "Time: Sun Nov 11 19:24:33 2018 Epoch: 140 Cost: 0.6898160576820374 Acc: 0.49863332509994507\n",
      "Time: Sun Nov 11 19:25:08 2018 Epoch: 150 Cost: 0.6870777606964111 Acc: 0.4987187385559082\n",
      "Time: Sun Nov 11 19:25:43 2018 Epoch: 160 Cost: 0.6898388862609863 Acc: 0.4987941086292267\n",
      "Time: Sun Nov 11 19:26:19 2018 Epoch: 170 Cost: 0.68669193983078 Acc: 0.4988611042499542\n",
      "Time: Sun Nov 11 19:26:54 2018 Epoch: 180 Cost: 0.686315655708313 Acc: 0.49892106652259827\n",
      "Time: Sun Nov 11 19:27:29 2018 Epoch: 190 Cost: 0.6849585175514221 Acc: 0.4990749955177307\n",
      "Time: Sun Nov 11 19:28:04 2018 Epoch: 200 Cost: 0.6840048432350159 Acc: 0.4994523823261261\n",
      "Time: Sun Nov 11 19:28:40 2018 Epoch: 210 Cost: 0.6812847852706909 Acc: 0.4998409152030945\n",
      "Time: Sun Nov 11 19:29:16 2018 Epoch: 220 Cost: 0.6835694909095764 Acc: 0.5001087188720703\n",
      "Time: Sun Nov 11 19:29:51 2018 Epoch: 230 Cost: 0.6826441884040833 Acc: 0.5008333325386047\n",
      "Time: Sun Nov 11 19:30:26 2018 Epoch: 240 Cost: 0.6811895370483398 Acc: 0.5015599727630615\n",
      "Time: Sun Nov 11 19:31:01 2018 Epoch: 250 Cost: 0.6804280877113342 Acc: 0.5024423003196716\n",
      "Time: Sun Nov 11 19:31:37 2018 Epoch: 260 Cost: 0.680884838104248 Acc: 0.5035926103591919\n",
      "Time: Sun Nov 11 19:32:13 2018 Epoch: 270 Cost: 0.6759494543075562 Acc: 0.5048750042915344\n",
      "Time: Sun Nov 11 19:32:48 2018 Epoch: 280 Cost: 0.6813127994537354 Acc: 0.50593101978302\n",
      "Time: Sun Nov 11 19:33:23 2018 Epoch: 290 Cost: 0.6790013313293457 Acc: 0.507099986076355\n",
      "Time: Sun Nov 11 19:33:58 2018 Epoch: 300 Cost: 0.6758444905281067 Acc: 0.5083870887756348\n",
      "Time: Sun Nov 11 19:34:32 2018 Epoch: 310 Cost: 0.6768007874488831 Acc: 0.5096094012260437\n",
      "Time: Sun Nov 11 19:35:07 2018 Epoch: 320 Cost: 0.6758994460105896 Acc: 0.5105606317520142\n",
      "Time: Sun Nov 11 19:35:41 2018 Epoch: 330 Cost: 0.6748630404472351 Acc: 0.5121029615402222\n",
      "Time: Sun Nov 11 19:36:16 2018 Epoch: 340 Cost: 0.6791088581085205 Acc: 0.5130714178085327\n",
      "Time: Sun Nov 11 19:36:51 2018 Epoch: 350 Cost: 0.6760091781616211 Acc: 0.5143471956253052\n",
      "Time: Sun Nov 11 19:37:26 2018 Epoch: 360 Cost: 0.6728048324584961 Acc: 0.5157567858695984\n",
      "Time: Sun Nov 11 19:38:01 2018 Epoch: 370 Cost: 0.6749691367149353 Acc: 0.5169210433959961\n",
      "Time: Sun Nov 11 19:38:35 2018 Epoch: 380 Cost: 0.6795783638954163 Acc: 0.5181282162666321\n",
      "Time: Sun Nov 11 19:39:10 2018 Epoch: 390 Cost: 0.6754032373428345 Acc: 0.5191500186920166\n",
      "Time: Sun Nov 11 19:39:45 2018 Epoch: 400 Cost: 0.6778891682624817 Acc: 0.5200244188308716\n",
      "Time: Sun Nov 11 19:40:20 2018 Epoch: 410 Cost: 0.6744056344032288 Acc: 0.5209285616874695\n",
      "Time: Sun Nov 11 19:40:54 2018 Epoch: 420 Cost: 0.6742671132087708 Acc: 0.5219767689704895\n",
      "Time: Sun Nov 11 19:41:29 2018 Epoch: 430 Cost: 0.6748540997505188 Acc: 0.5233636498451233\n",
      "Time: Sun Nov 11 19:42:05 2018 Epoch: 440 Cost: 0.6754420399665833 Acc: 0.5244110822677612\n",
      "Time: Sun Nov 11 19:42:41 2018 Epoch: 450 Cost: 0.6652225255966187 Acc: 0.5257173776626587\n",
      "Time: Sun Nov 11 19:43:16 2018 Epoch: 460 Cost: 0.6764179468154907 Acc: 0.5265212655067444\n",
      "Time: Sun Nov 11 19:43:51 2018 Epoch: 470 Cost: 0.6707913279533386 Acc: 0.5278021097183228\n",
      "Time: Sun Nov 11 19:44:26 2018 Epoch: 480 Cost: 0.6732090711593628 Acc: 0.5287857055664062\n",
      "Time: Sun Nov 11 19:45:01 2018 Epoch: 490 Cost: 0.675946831703186 Acc: 0.529670000076294\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session(config = config)\n",
    "train_writer = tf.summary.FileWriter( '/home/oktogen/Desktop/DeepLearningExperiments/CNN/CatsVsDogs/Logs', sess.graph)\n",
    "saver = tf.train.Saver()\n",
    "sess.run(init)\n",
    "sess.run(tf.local_variables_initializer())\n",
    "print('Session starting {}'.format(time.ctime()))\n",
    "for i in range(500):\n",
    "    X, Y = random_X_and_Y()\n",
    "    sess.run(optimizer, feed_dict={ X_: X, Y_:Y})\n",
    "    if i % 10 == 0:\n",
    "        cost_  = sess.run(cost, feed_dict={ X_: X, Y_:Y})\n",
    "        sess.run([accuracy, acc_op], feed_dict={ X_: X, Y_:Y})\n",
    "        acc= sess.run(accuracy, feed_dict={ X_: X, Y_:Y})\n",
    "        sum_acc, sum_cost = sess.run([summary_accuracy, summary_cost], feed_dict={ X_: X, Y_:Y})\n",
    "        train_writer.add_summary(sum_cost, i)\n",
    "        train_writer.add_summary(sum_acc, i)\n",
    "        print('Time: {} Epoch: {} Cost: {} Acc: {}'.format(time.ctime(), i, cost_, acc) )\n",
    "        saver.save(sess, '/home/oktogen/Desktop/DeepLearningExperiments/CNN/CatsVsDogs/Model/TF',global_step = i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init = tf.global_variables_initializer()\n",
    "X, Y = random_X_and_Y()\n",
    "res = sess.run(logits,feed_dict={ X_: X})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: Tue Nov 20 07:00:23 2018 Epoch: 200000 Cost: 0.5237043499946594 Acc: 0.9106477499008179\n",
      "Time: Tue Nov 20 07:28:16 2018 Epoch: 200500 Cost: 0.5212043523788452 Acc: 0.910766065120697\n",
      "Time: Tue Nov 20 07:56:15 2018 Epoch: 201000 Cost: 0.5202043652534485 Acc: 0.9108882546424866\n",
      "Time: Tue Nov 20 08:24:08 2018 Epoch: 201500 Cost: 0.5272043347358704 Acc: 0.9109790325164795\n",
      "Time: Tue Nov 20 08:52:03 2018 Epoch: 202000 Cost: 0.5267044305801392 Acc: 0.9110715985298157\n",
      "Time: Tue Nov 20 09:20:19 2018 Epoch: 202500 Cost: 0.5262043476104736 Acc: 0.9111659526824951\n",
      "Time: Tue Nov 20 09:48:31 2018 Epoch: 203000 Cost: 0.5247043967247009 Acc: 0.9112664461135864\n",
      "Time: Tue Nov 20 10:16:43 2018 Epoch: 203500 Cost: 0.5217044353485107 Acc: 0.9113796353340149\n",
      "Time: Tue Nov 20 10:44:56 2018 Epoch: 204000 Cost: 0.5162043571472168 Acc: 0.9115163683891296\n",
      "Time: Tue Nov 20 11:13:08 2018 Epoch: 204500 Cost: 0.5217043161392212 Acc: 0.9116285443305969\n",
      "Time: Tue Nov 20 11:41:19 2018 Epoch: 205000 Cost: 0.5267043709754944 Acc: 0.911718487739563\n",
      "Time: Tue Nov 20 12:09:29 2018 Epoch: 205500 Cost: 0.5227043628692627 Acc: 0.9118253588676453\n",
      "Time: Tue Nov 20 12:37:21 2018 Epoch: 206000 Cost: 0.5187044143676758 Acc: 0.9119491577148438\n",
      "Time: Tue Nov 20 13:05:32 2018 Epoch: 206500 Cost: 0.5242044925689697 Acc: 0.9120485782623291\n",
      "Time: Tue Nov 20 13:33:32 2018 Epoch: 207000 Cost: 0.52120441198349 Acc: 0.9121605753898621\n",
      "Time: Tue Nov 20 14:01:46 2018 Epoch: 207500 Cost: 0.524204432964325 Acc: 0.9122591614723206\n",
      "Time: Tue Nov 20 14:29:42 2018 Epoch: 208000 Cost: 0.5207043886184692 Acc: 0.9123722910881042\n",
      "Time: Tue Nov 20 14:57:54 2018 Epoch: 208500 Cost: 0.5222043991088867 Acc: 0.9124785661697388\n",
      "Time: Tue Nov 20 15:26:03 2018 Epoch: 209000 Cost: 0.5262043476104736 Acc: 0.9125673174858093\n",
      "Time: Tue Nov 20 15:54:17 2018 Epoch: 209500 Cost: 0.5187044143676758 Acc: 0.9126876592636108\n",
      "Time: Tue Nov 20 16:22:28 2018 Epoch: 210000 Cost: 0.5262043476104736 Acc: 0.9127755165100098\n",
      "Time: Tue Nov 20 16:50:38 2018 Epoch: 210500 Cost: 0.5132043957710266 Acc: 0.9129182696342468\n",
      "Time: Tue Nov 20 17:18:51 2018 Epoch: 211000 Cost: 0.5182043313980103 Acc: 0.9130392074584961\n"
     ]
    }
   ],
   "source": [
    "for i in range(200000, 250000):\n",
    "    X, Y = random_X_and_Y()\n",
    "    sess.run(optimizer, feed_dict={ X_: X, Y_:Y})\n",
    "    if i % 500 == 0:\n",
    "        cost_  = sess.run(cost, feed_dict={ X_: X, Y_:Y})\n",
    "        sess.run([accuracy, acc_op], feed_dict={ X_: X, Y_:Y})\n",
    "        acc= sess.run(accuracy, feed_dict={ X_: X, Y_:Y})\n",
    "        sum_acc, sum_cost = sess.run([summary_accuracy, summary_cost], feed_dict={ X_: X, Y_:Y})\n",
    "        train_writer.add_summary(sum_cost, i)\n",
    "        train_writer.add_summary(sum_acc, i)\n",
    "        print('Time: {} Epoch: {} Cost: {} Acc: {}'.format(time.ctime(), i, cost_, acc) )\n",
    "        saver.save(sess, '/home/oktogen/Desktop/DeepLearningExperiments/CNN/CatsVsDogs/Model/TF',global_step = i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

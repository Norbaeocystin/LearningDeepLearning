{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN classification of MNIST dataset ( Code is heavily inspired by book TensorFlow 1.x Deep Learning Cookbook )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import time\n",
    "\n",
    "def get_mnist():\n",
    "    '''\n",
    "    returns mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels\n",
    "    '''\n",
    "    mnist = input_data.read_data_sets('MNIST_data/', one_hot = True)\n",
    "    return mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels\n",
    "\n",
    "def display_digit(num, x, y):\n",
    "    '''\n",
    "    display image from mnist data\n",
    "    '''\n",
    "    label = y[num].argmax(axis = 0)\n",
    "    image = x[num].reshape([28,28])\n",
    "    plt.tile('Example: {} Label: {}'.format(num, label))\n",
    "    plt.imshow(image, cmap = plt.get_cmap('gray_r'))\n",
    "    plt.show()\n",
    "    \n",
    "class CNNModel():\n",
    "    '''\n",
    "    Convolutional Neural Network\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, learning_rate = 0.01, n_input = 784, n_hidden = 20, classes = 10, dropout = 0.85):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_input = n_input\n",
    "        self.classes = classes\n",
    "        self.dropout = dropout\n",
    "        # placeholders\n",
    "        self.X = tf.placeholder(tf.float32,[None, self.n_input], name = 'X')\n",
    "        self.Y = tf.placeholder(tf.float32, [None, self.classes], name = 'Y')\n",
    "        self.x = tf.reshape(self.X, shape = [-1, 28, 28, 1])\n",
    "        self.keep_prob = tf.placeholder(tf.float32)\n",
    "        #variables\n",
    "        self.w1 = tf.Variable(tf.random_normal([5,5,1,32]))\n",
    "        self.b1 = tf.Variable(tf.random_normal([32]))\n",
    "        self.w2 = tf.Variable(tf.random_normal([5,5,32,64]))\n",
    "        self.b2 = tf.Variable(tf.random_normal([64]))\n",
    "        self.w3 = tf.Variable(tf.random_normal([7*7*64, 1024]))\n",
    "        self.b3 = tf.Variable(tf.random_normal([1024]))\n",
    "        self.w4 = tf.Variable(tf.random_normal([1024, self.classes]))\n",
    "        self.b4 = tf.Variable(tf.random_normal([self.classes]))\n",
    "        #layers\n",
    "        self.conv1 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(self.x, self.w1, strides = [1,1,1,1], padding = 'SAME'), self.b1))\n",
    "        self.maxpool1 = tf.nn.max_pool(self.conv1, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "        self.conv2 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(self.maxpool1, self.w2, strides = [1,1,1,1], padding = 'SAME'), self.b2))\n",
    "        self.maxpool2 = tf.nn.max_pool(self.conv2, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "        self.fc1 = tf.reshape(self.maxpool2, [-1, self.w3.get_shape().as_list()[0]])\n",
    "        self.fc2 = tf.add(tf.matmul(self.fc1, self.w3), self.b3)\n",
    "        self.fc3 = tf.nn.relu(self.fc2)\n",
    "        self.fc4 = tf.nn.dropout(self.fc3, self.dropout)\n",
    "        # prediction \n",
    "        self.Y_hat = tf.add(tf.matmul(self.fc4, self.w4), self.b4)\n",
    "        #loss and optimization\n",
    "        self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = self.Y, logits = self.Y_hat, name = 'loss'))\n",
    "        self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
    "        # accuracy\n",
    "        self.correct_prediction = tf.equal(tf.argmax(self.Y_hat, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "        # for tensorboard\n",
    "        self.loss_scalar = tf.summary.scalar('cross-entropy', self.loss)\n",
    "        self.accuracy_scalar = tf.summary.scalar('accuracy', self.accuracy)\n",
    "        # inititialization and session stuff\n",
    "        self.init_op = tf.global_variables_initializer()\n",
    "        self.sess = tf.Session()\n",
    "        \n",
    "    def fit(self, X, Y, epochs = 100, every = 10, folder = 'MNIST_CNN_log', batch_size = 500, init = True ):\n",
    "        '''\n",
    "        optimizes weights\n",
    "        args:\n",
    "          X: <numpy.array>, features \n",
    "          Y: <numpy.array>, labels\n",
    "          epochs: <int>, number of epochs\n",
    "          every: <int>, how often print message with Epoch and Loss values\n",
    "          folder: <string>, name of folder where to store data for TensorBoard\n",
    "          batch_size: <int>, size of features array, size of features sample\n",
    "        '''\n",
    "        total = []\n",
    "        if init:\n",
    "            self.sess.run(self.init_op)\n",
    "        summary_writer = tf.summary.FileWriter(folder, self.sess.graph)\n",
    "        x_length = len(X)\n",
    "        for i in range(epochs):\n",
    "            batch = np.random.randint(0, x_length - batch_size, 1)[0]\n",
    "            x_batch = X[batch:batch + batch_size]\n",
    "            y_batch = Y[batch:batch + batch_size]\n",
    "            _, l, a = self.sess.run([self.optimizer, self.loss, self.accuracy], feed_dict = {self.X: x_batch, self.Y: y_batch})\n",
    "            loss, accuracy = self.sess.run([self.loss_scalar, self.accuracy_scalar], feed_dict = {self.X: x_batch, self.Y: y_batch})\n",
    "            summary_writer.add_summary(loss, i)\n",
    "            summary_writer.add_summary(accuracy, i)\n",
    "            total.append(l)\n",
    "            if i % every == 0:\n",
    "                print('[ {} ] Epoch {} Loss: {:.7f} Accuracy:{:.3f}'.format(time.ctime(), i, l, a))\n",
    "        return total\n",
    "    \n",
    "    def predict(self, X, before_fit = False):\n",
    "        '''\n",
    "        return predicted values, \n",
    "        \n",
    "        args:\n",
    "          X: <numpy.array>, features\n",
    "          before_fit: <boolean>, change to True if you want to use before calling fit method\n",
    "        '''\n",
    "        if before_fit:\n",
    "            self.sess.run(self.init_op)\n",
    "        Y_hat = self.sess.run(self.Y_hat, feed_dict = {self.X: X})\n",
    "        return Y_hat\n",
    "    \n",
    "    def show(self, values):\n",
    "        '''\n",
    "        plot graph\n",
    "        \n",
    "        args:\n",
    "          values: <list>, list or array of values to be plotted\n",
    "        '''\n",
    "        plt.plot(values)\n",
    "        plt.show()\n",
    "    \n",
    "    def close_session(self):\n",
    "        '''\n",
    "        closes tensorflow session\n",
    "        '''\n",
    "        self.sess.close()\n",
    "        return True\n",
    "    \n",
    "    def close_and_reset(self):\n",
    "        '''\n",
    "        closes tensorflow session, clears the default graph stack and resets the global default graph.\n",
    "        '''\n",
    "        self.sess.close()\n",
    "        tf.reset_default_graph()\n",
    "        return True\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = get_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Thu Dec 27 00:08:03 2018 ] Epoch 0 Loss: 69157.5234375 Accuracy:0.000\n",
      "[ Thu Dec 27 00:08:05 2018 ] Epoch 10 Loss: 13446.7626953 Accuracy:0.500\n",
      "[ Thu Dec 27 00:08:07 2018 ] Epoch 20 Loss: 10302.3808594 Accuracy:0.500\n",
      "[ Thu Dec 27 00:08:09 2018 ] Epoch 30 Loss: 926.8220825 Accuracy:0.700\n",
      "[ Thu Dec 27 00:08:11 2018 ] Epoch 40 Loss: 1193.2971191 Accuracy:0.900\n",
      "[ Thu Dec 27 00:08:13 2018 ] Epoch 50 Loss: 2025.1921387 Accuracy:0.600\n",
      "[ Thu Dec 27 00:08:15 2018 ] Epoch 60 Loss: 7.5712891 Accuracy:0.900\n",
      "[ Thu Dec 27 00:08:17 2018 ] Epoch 70 Loss: 1804.8996582 Accuracy:0.700\n",
      "[ Thu Dec 27 00:08:20 2018 ] Epoch 80 Loss: 699.7945557 Accuracy:0.700\n",
      "[ Thu Dec 27 00:08:22 2018 ] Epoch 90 Loss: 0.0000000 Accuracy:1.000\n"
     ]
    }
   ],
   "source": [
    "nn = CNNModel()\n",
    "losses = nn.fit(X_train, Y_train, epochs = 100, every = 10, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
